{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  rows analyzed.\n",
      "2000  rows analyzed.\n",
      "3000  rows analyzed.\n",
      "4000  rows analyzed.\n",
      "5000  rows analyzed.\n",
      "6000  rows analyzed.\n",
      "7000  rows analyzed.\n",
      "8000  rows analyzed.\n",
      "9000  rows analyzed.\n",
      "10000  rows analyzed.\n",
      "11000  rows analyzed.\n",
      "12000  rows analyzed.\n",
      "13000  rows analyzed.\n",
      "14000  rows analyzed.\n",
      "15000  rows analyzed.\n",
      "16000  rows analyzed.\n",
      "17000  rows analyzed.\n",
      "18000  rows analyzed.\n",
      "19000  rows analyzed.\n",
      "20000  rows analyzed.\n",
      "21000  rows analyzed.\n",
      "22000  rows analyzed.\n",
      "23000  rows analyzed.\n",
      "24000  rows analyzed.\n",
      "25000  rows analyzed.\n",
      "26000  rows analyzed.\n",
      "27000  rows analyzed.\n",
      "28000  rows analyzed.\n",
      "29000  rows analyzed.\n",
      "30000  rows analyzed.\n",
      "31000  rows analyzed.\n",
      "32000  rows analyzed.\n",
      "33000  rows analyzed.\n",
      "34000  rows analyzed.\n",
      "35000  rows analyzed.\n",
      "36000  rows analyzed.\n",
      "37000  rows analyzed.\n",
      "38000  rows analyzed.\n",
      "39000  rows analyzed.\n",
      "40000  rows analyzed.\n",
      "41000  rows analyzed.\n",
      "42000  rows analyzed.\n",
      "43000  rows analyzed.\n",
      "44000  rows analyzed.\n",
      "45000  rows analyzed.\n",
      "46000  rows analyzed.\n",
      "47000  rows analyzed.\n",
      "48000  rows analyzed.\n",
      "49000  rows analyzed.\n",
      "50000  rows analyzed.\n",
      "51000  rows analyzed.\n",
      "52000  rows analyzed.\n",
      "53000  rows analyzed.\n",
      "54000  rows analyzed.\n",
      "55000  rows analyzed.\n",
      "56000  rows analyzed.\n",
      "57000  rows analyzed.\n",
      "58000  rows analyzed.\n",
      "59000  rows analyzed.\n",
      "60000  rows analyzed.\n",
      "61000  rows analyzed.\n",
      "62000  rows analyzed.\n",
      "63000  rows analyzed.\n",
      "64000  rows analyzed.\n",
      "65000  rows analyzed.\n",
      "66000  rows analyzed.\n",
      "67000  rows analyzed.\n",
      "68000  rows analyzed.\n",
      "69000  rows analyzed.\n",
      "70000  rows analyzed.\n",
      "71000  rows analyzed.\n",
      "72000  rows analyzed.\n",
      "73000  rows analyzed.\n",
      "74000  rows analyzed.\n",
      "75000  rows analyzed.\n",
      "76000  rows analyzed.\n",
      "77000  rows analyzed.\n",
      "78000  rows analyzed.\n",
      "79000  rows analyzed.\n",
      "80000  rows analyzed.\n",
      "81000  rows analyzed.\n",
      "82000  rows analyzed.\n",
      "83000  rows analyzed.\n",
      "84000  rows analyzed.\n",
      "85000  rows analyzed.\n",
      "86000  rows analyzed.\n",
      "87000  rows analyzed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ccd344e58a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m#             print(str(lowerkop).split())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memolex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowerkop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m#                     print(\"FOUND \", word[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EMOLEX\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "firstrow=[\"Medium\", \"Datum\", \"Kop\", \"URL\", \"Positive count\", \"Positive list\", \"Negative count\", \"Negative list\", \"Anger count\", \"Anger list\", \"Anticipation count\", \"Anticipation\", \"Disgust count\", \"Disgust list\", \"Fear count\", \"Fear list\", \"Joy count\", \"Joy list\", \"Sadness count\", \"Sadness list\", \"Surprise count\", \"Surprise list\", \"Trust count\", \"Trust list\"]\n",
    "medium = \"\"\n",
    "datum = \"\"\n",
    "kop = \"\"\n",
    "url = \"\"\n",
    "poslst = []\n",
    "neglst = []\n",
    "anglst = []\n",
    "antlst = []\n",
    "dislst = []\n",
    "fealst = []\n",
    "joylst = []\n",
    "sadlst = []\n",
    "surlst = []\n",
    "trulst = []\n",
    "poscnt = 0\n",
    "negcnt = 0\n",
    "angcnt = 0\n",
    "antcnt = 0\n",
    "discnt = 0\n",
    "feacnt = 0\n",
    "joycnt = 0\n",
    "sadcnt = 0\n",
    "surcnt = 0\n",
    "trucnt = 0\n",
    "\n",
    "# Create destination csv\n",
    "with open('Emolex results.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Emolex results.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "count = 0\n",
    "subcount = 0\n",
    "        \n",
    "# Open data\n",
    "with open('ALLE DATA def.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "\n",
    "    for row in data:\n",
    "        poslst = []\n",
    "        neglst = []\n",
    "        anglst = []\n",
    "        antlst = []\n",
    "        dislst = []\n",
    "        fealst = []\n",
    "        joylst = []\n",
    "        sadlst = []\n",
    "        surlst = []\n",
    "        trulst = []\n",
    "        poscnt = 0\n",
    "        negcnt = 0\n",
    "        angcnt = 0\n",
    "        antcnt = 0\n",
    "        discnt = 0\n",
    "        feacnt = 0\n",
    "        joycnt = 0\n",
    "        sadcnt = 0\n",
    "        surcnt = 0\n",
    "        trucnt = 0\n",
    "\n",
    "        medium = row[0]\n",
    "        datum = row[1]\n",
    "        kop = row[2]\n",
    "        url = row[3]\n",
    "\n",
    "        lowerkop = re.sub('[^A-Za-z0-9 ]+', '', kop).lower()\n",
    "\n",
    "        # Open emolex\n",
    "        with open('Emolex PRE BLACKLIST.csv', 'r', encoding=\"utf-8\") as y:\n",
    "            emolex = csv.reader(y, delimiter=',', quotechar='|')\n",
    "#             print(str(lowerkop).split())\n",
    "            \n",
    "            for word in emolex:\n",
    "                if word[0] in str(lowerkop).split():\n",
    "#                     print(\"FOUND \", word[0])\n",
    "                    # positive\n",
    "                    if word[1] != \"\":\n",
    "                        poslst.append(word[0])\n",
    "                        poscnt += 1\n",
    "                    # negative\n",
    "                    if word[2] != \"\":\n",
    "                        neglst.append(word[0])\n",
    "                        negcnt += 1\n",
    "                    # anger\n",
    "                    if word[3] != \"\":\n",
    "                        anglst.append(word[0])\n",
    "                        angcnt += 1\n",
    "                    # anticipation\n",
    "                    if word[4] != \"\":\n",
    "                        antlst.append(word[0])\n",
    "                        antcnt += 1\n",
    "                    # disgust\n",
    "                    if word[5] != \"\":\n",
    "                        dislst.append(word[0])\n",
    "                        discnt += 1\n",
    "                    # fear\n",
    "                    if word[6] != \"\":\n",
    "                        fealst.append(word[0])\n",
    "                        feacnt += 1\n",
    "                    # joy\n",
    "                    if word[7] != \"\":\n",
    "                        joylst.append(word[0])\n",
    "                        joycnt += 1\n",
    "                    # sadness\n",
    "                    if word[8] != \"\":\n",
    "                        sadlst.append(word[0])\n",
    "                        sadcnt += 1\n",
    "                    # surprise\n",
    "                    if word[9] != \"\":\n",
    "                        surlst.append(word[0])\n",
    "                        surcnt += 1\n",
    "                    # trust\n",
    "                    if word[10] != \"\":\n",
    "                        trulst.append(word[0])\n",
    "                        trucnt += 1\n",
    "            nextrow = [medium,datum,kop,url,poscnt,poslst,negcnt,neglst,angcnt,anglst,antcnt,antlst,discnt,dislst,feacnt,fealst,joycnt,joylst,sadcnt,sadlst,surcnt,surlst,trucnt,trulst]\n",
    "            csv_add(nextrow)\n",
    "            count += 1\n",
    "            if count == 1000:\n",
    "                subcount += 1\n",
    "                count = 0\n",
    "                print(subcount*1000,\" rows analyzed.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv ready.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# EMOLEX RESULTS READER WITHOUT DISTINGUISHING BETWEEN MEDIA\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "wrd = \"\"\n",
    "frq = \"\"\n",
    "poslst = []\n",
    "neglst = []\n",
    "anglst = []\n",
    "antlst = []\n",
    "dislst = []\n",
    "fealst = []\n",
    "joylst = []\n",
    "sadlst = []\n",
    "surlst = []\n",
    "trulst = []\n",
    "\n",
    "firstrow = [\"Word\",\"Frequency\"]\n",
    "\n",
    "# Create destination csv\n",
    "with open('Emolex-freqs.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Emolex-freqs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\".csv ready.\")\n",
    "        \n",
    "# Open data\n",
    "with open('Emolex results.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "    for row in data:\n",
    "        for word in row[5].strip('][').split(', '):\n",
    "            poslst.append(word)\n",
    "        for word in row[7].strip('][').split(', '):\n",
    "            neglst.append(word)\n",
    "        for word in row[9].strip('][').split(', '):\n",
    "            anglst.append(word)\n",
    "        for word in row[11].strip('][').split(', '):\n",
    "            antlst.append(word)\n",
    "        for word in row[13].strip('][').split(', '):\n",
    "            dislst.append(word)\n",
    "        for word in row[15].strip('][').split(', '):\n",
    "            fealst.append(word)\n",
    "        for word in row[17].strip('][').split(', '):\n",
    "            joylst.append(word)\n",
    "        for word in row[19].strip('][').split(', '):\n",
    "            sadlst.append(word)\n",
    "        for word in row[21].strip('][').split(', '):\n",
    "            surlst.append(word)\n",
    "        for word in row[23].strip('][').split(', '):\n",
    "            trulst.append(word)\n",
    "\n",
    "\n",
    "poscnt = Counter(poslst).most_common(101)\n",
    "csv_add([\"POSITIVE\"])\n",
    "for i in poscnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "negcnt = Counter(neglst).most_common(101)\n",
    "csv_add([\"NEGATIVE\"])\n",
    "for i in negcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "angcnt = Counter(anglst).most_common(101)\n",
    "csv_add([\"ANGER\"])\n",
    "for i in angcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "antcnt = Counter(antlst).most_common(101)\n",
    "csv_add([\"ANTICIPATION\"])\n",
    "for i in antcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "discnt = Counter(dislst).most_common(101)\n",
    "csv_add([\"DISGUST\"])\n",
    "for i in discnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "feacnt = Counter(fealst).most_common(101)\n",
    "csv_add([\"FEAR\"])\n",
    "for i in feacnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "joycnt = Counter(joylst).most_common(101)\n",
    "csv_add([\"JOY\"])\n",
    "for i in joycnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "sadcnt = Counter(sadlst).most_common(101)\n",
    "csv_add([\"SADNESS\"])\n",
    "for i in sadcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "surcnt = Counter(surlst).most_common(101)\n",
    "csv_add([\"SURPRISE\"])\n",
    "for i in surcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "trucnt = Counter(trulst).most_common(101)\n",
    "csv_add([\"TRUST\"])\n",
    "for i in trucnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv ready.\n",
      "Lists made.\n",
      "[('goed[1]', 679), ('houdt[2]', 405), ('Spelen[1]', 399), ('hoop[1]', 240), ('beste[1]', 202), ('winst[2]', 160), ('blij[3]', 148), ('welkom[1]', 140), ('hoopt[1]', 136), ('Welkom[1]', 112), ('goed[1][NegatedDueToPreviousWord]', 111), ('speelt[1]', 104), ('spelen[1]', 104), ('vertrouwen[1]', 99), ('prijs[2]', 84), ('succes[2]', 77), ('Grand[1]', 70), ('Lichte[1]', 65), ('lichte[1]', 59), ('mooie[2]', 58), ('rustig[1]', 57), ('welkom[1][NegatedDueToPreviousWord]', 48), ('veilige[1]', 45), ('bonus[1]', 43), ('genieten[2]', 42), ('trots[1]', 41), ('hield[3]', 41), ('hou[3]', 40), ('geloof[1]', 40), ('behandeling[1]', 38), ('tevreden[1]', 35), ('rente[1]', 33), ('geluk[2]', 29), ('baby[1]', 29), ('speciale[1]', 27), ('blij[3][NegatedDueToPreviousWord][-1', 27), ('Pride[1]', 27), ('ware[1]', 26), ('rijke[1]', 25), ('Super[2]', 25), ('lief[1]', 23), ('eerlijk[2]', 23), ('lachen[1]', 23), ('Hoop[1]', 23), ('Prijs[2]', 22), ('held[2]', 21), ('Goed[1]', 21), ('populaire[2]', 20), ('beloning[1]', 20), ('perfecte[1]', 20), ('talent[1]', 19), ('Vertrouwen[1]', 19), ('lol[1]', 16), ('Mooie[2]', 16), ('goed[1][1', 16), ('Houdt[2]', 15), ('knuffel[2]', 15), ('plezier[2]', 15), ('respect[2]', 15), ('Winst[2]', 14), ('enthousiast[2]', 14), ('lieve[1]', 13), ('geliefde[2]', 13), ('Bonus[1]', 13), ('dank[1]', 12), ('slagen[2]', 12), ('humor[2]', 12), ('wijs[1]', 12), ('Hou[3]', 11), ('ontspannen[2]', 11), ('zonnig[1]', 11), ('Love[2]', 11), ('slimme[1]', 11), ('eer[2]', 10), ('geweldig[3]', 10), ('verbetering[1]', 10), ('Baby[1]', 10), ('Speciale[1]', 9), ('vreugde[2]', 9), ('hoopte[1]', 9), ('Succes[2]', 9), ('prachtige[2]', 9), ('Trots[1]', 9), ('zachte[1]', 8), ('x[1]', 8), ('sexy[2]', 8), ('blij[3][1', 8), ('oprichter[1]', 8), ('Kick[3]', 8), ('knap[1]', 8), ('super[2]', 8), ('handig[1]', 8), ('kalm[1]', 7), ('Joke[1]', 7), ('Rock[1]', 7), ('X[1]', 7), ('onschuldig[1]', 7), ('Rijke[1]', 7), ('vrijstelling[1]', 7), ('glimlach[2]', 7)]\n",
      "[('niet[-2]', 6454), ('over[-1]', 4212), ('tegen[-1]', 2313), ('meer[-1]', 2095), ('terug[-1]', 854), ('meer[-1][NegatedDueToPreviousWord]', 685), ('houden[-1]', 476), ('Meer[-1]', 424), ('crisis[-2]', 417), ('doden[-2]', 306), ('strijd[-2]', 279), ('daling[-1]', 230), ('vast[-1]', 224), ('dood[-2]', 210), ('angst[-3]', 172), ('Niet[-2]', 168), ('getroffen[-1]', 156), ('verlies[-2]', 152), ('niet[-2][--1', 144), ('protest[-1]', 140), ('sluiten[-1]', 138), ('over[-1][NegatedDueToPreviousWord]', 134), ('ziek[-3]', 130), ('tekort[-1]', 126), ('verliest[-1]', 124), ('drukte[-1]', 124), ('tijdelijk[-1]', 122), ('stoppen[-1]', 118), ('geweld[-3]', 117), ('vrezen[-2]', 109), ('mis[-1]', 108), ('strenge[-1]', 104), ('schade[-2]', 103), ('slecht[-1]', 102), ('bang[-3]', 96), ('harde[-1]', 88), ('ontslagen[-2]', 85), ('meer[-1][--1', 85), ('negatieve[-1]', 81), ('zieke[-1]', 76), ('niet[-2][-1', 76), ('probleem[-1]', 75), ('pijn[-1]', 75), ('epidemie[-1]', 72), ('oorlog[-2]', 72), ('ontslag[-1]', 72), ('paniek[-2]', 70), ('chaos[-1]', 69), ('ramp[-3]', 69), ('alarm[-2]', 66), ('ziekte[-1]', 65), ('lijdt[-3]', 65), ('gebrek[-1]', 65), ('alsof[-1]', 64), ('weigeren[-1]', 64), ('Over[-1]', 63), ('onrust[-1]', 62), ('Drukte[-1]', 62), ('tegen[-1][NegatedDueToPreviousWord]', 61), ('verliezen[-2]', 60), ('verlaten[-1]', 60), ('Terug[-1]', 59), ('Ernst[-1]', 59), ('vertraging[-1]', 58), ('fout[-2]', 57), ('negeren[-1]', 54), ('recessie[-1]', 53), ('Daling[-1]', 53), ('verdachte[-1]', 52), ('gevangenis[-1]', 51), ('worstelen[-1]', 51), ('tranen[-3]', 50), ('arme[-1]', 50), ('failliet[-2]', 49), ('terug[-1][NegatedDueToPreviousWord]', 49), ('dode[-2]', 47), ('verkeerde[-1]', 47), ('ernstige[-1]', 47), ('Onrust[-1]', 46), ('illegale[-1]', 45), ('onduidelijk[-1]', 45), ('twijfel[-1]', 44), ('nood[-2]', 43), ('val[-1]', 43), ('achterstand[-1]', 42), ('fraude[-1]', 42), ('vond[-1]', 41), ('ruzie[-2]', 41), ('bloot[-1]', 41), ('overlijden[-1]', 41), ('Angst[-3]', 41), ('explosie[-1]', 40), ('Chaos[-1]', 40), ('spanning[-2]', 39), ('wantrouwen[-1]', 39), ('beperken[-1]', 38), ('lijden[-3]', 38), ('onderzoeken[-1]', 38), ('storm[-1]', 38), ('bestrijding[-1]', 37)]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# SENTISTRENGTH RESULTS READER\n",
    "\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "firstrow = [\"Word\",\"Frequency\"]\n",
    "neglst = []\n",
    "poslst = []\n",
    "\n",
    "# Create destination csv\n",
    "with open('Senti-freqs.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Senti-freqs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\".csv ready.\")\n",
    "\n",
    "with open('Koppen voor Sentistrength+results.txt', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter='\t', quotechar='|')\n",
    "    for row in data:\n",
    "        wordlist = []\n",
    "        for word in row[4].split(\" \"):\n",
    "            if \"[-4]\" in word:\n",
    "                neglst.append(word)\n",
    "            if \"[-3]\" in word:\n",
    "                neglst.append(word)\n",
    "            if \"[-2]\" in word:\n",
    "                neglst.append(word)\n",
    "            if \"[-1]\" in word:\n",
    "                neglst.append(word)\n",
    "            if \"[4]\" in word:\n",
    "                poslst.append(word)\n",
    "            if \"[3]\" in word:\n",
    "                poslst.append(word)\n",
    "            if \"[2]\" in word:\n",
    "                poslst.append(word)\n",
    "            if \"[1]\" in word:\n",
    "                poslst.append(word)\n",
    "\n",
    "print(\"Lists made.\")\n",
    "                \n",
    "poscnt = Counter(poslst).most_common(100)\n",
    "print(poscnt)\n",
    "csv_add([\"POSITIVE\"])\n",
    "for i in poscnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,-]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "negcnt = Counter(neglst).most_common(100)\n",
    "print(negcnt)\n",
    "csv_add([\"NEGATIVE\"])\n",
    "for i in negcnt[1:]:\n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,-]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = listitem[0]\n",
    "    frq = listitem[1]\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.nl import sentiment\n",
    "import csv\n",
    "\n",
    "firstrow = ['Kop','translatedkop','pos','neg','comments','pattern']\n",
    "kop = \"\"\n",
    "kop2 = \"\"\n",
    "pos = \"\"\n",
    "neg = \"\"\n",
    "com = \"\"\n",
    "pattern = \"\"\n",
    "\n",
    "# Create destination csv\n",
    "with open('Random500results.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Random500results.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Open data\n",
    "with open('Random500+results.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter='\t', quotechar='|')\n",
    "    for row in data:\n",
    "        kop = row[0]\n",
    "        kop2 = row[1]\n",
    "        pos = row[2]\n",
    "        neg = row[3]\n",
    "        com = row[4]\n",
    "        score = sentiment(kop)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [kop,kop2,pos,neg,com,pattern]\n",
    "        csv_add(nextrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  100\n",
      "Progress:  200\n",
      "Progress:  300\n",
      "Progress:  400\n",
      "Progress:  500\n",
      "Progress:  600\n",
      "Progress:  700\n",
      "Progress:  800\n",
      "Progress:  900\n",
      "Progress:  1000\n",
      "Progress:  1100\n",
      "Progress:  1200\n",
      "Progress:  1300\n",
      "Progress:  1400\n",
      "Progress:  1500\n",
      "Progress:  1600\n",
      "Progress:  1700\n",
      "Progress:  1800\n",
      "Progress:  1900\n",
      "Progress:  2000\n",
      "Progress:  2100\n",
      "Progress:  2200\n",
      "Progress:  2300\n",
      "Progress:  2400\n",
      "Progress:  2500\n",
      "Progress:  2600\n",
      "Progress:  2700\n",
      "Progress:  2800\n",
      "Progress:  2900\n",
      "Progress:  3000\n",
      "Progress:  3100\n",
      "Progress:  3200\n",
      "Progress:  3300\n",
      "Progress:  3400\n",
      "Progress:  3500\n",
      "Progress:  3600\n",
      "Progress:  3700\n",
      "Progress:  3800\n",
      "Progress:  3900\n",
      "Progress:  4000\n",
      "Progress:  4100\n",
      "Progress:  4200\n",
      "Progress:  4300\n",
      "Progress:  4400\n",
      "Progress:  4500\n",
      "Progress:  4600\n",
      "Progress:  4700\n",
      "Progress:  4800\n",
      "Progress:  4900\n",
      "Progress:  5000\n",
      "Progress:  5100\n",
      "Progress:  5200\n",
      "Progress:  5300\n",
      "Progress:  5400\n",
      "Progress:  5500\n",
      "Progress:  5600\n",
      "Progress:  5700\n",
      "Progress:  5800\n",
      "Progress:  5900\n",
      "Progress:  6000\n",
      "Progress:  6100\n",
      "Progress:  6200\n",
      "Progress:  6300\n",
      "Progress:  6400\n",
      "Progress:  6500\n",
      "Progress:  6600\n",
      "Progress:  6700\n",
      "Progress:  6800\n",
      "Progress:  6900\n",
      "Progress:  7000\n",
      "Progress:  7100\n",
      "Progress:  7200\n",
      "Progress:  7300\n",
      "Progress:  7400\n",
      "Progress:  7500\n",
      "Progress:  7600\n",
      "Progress:  7700\n",
      "Progress:  7800\n",
      "Progress:  7900\n",
      "Progress:  8000\n",
      "Progress:  8100\n",
      "Progress:  8200\n",
      "Progress:  8300\n",
      "Progress:  8400\n",
      "Progress:  8500\n",
      "Progress:  8600\n",
      "Progress:  8700\n",
      "Progress:  8800\n",
      "Progress:  8900\n",
      "Progress:  9000\n",
      "Progress:  9100\n",
      "Progress:  9200\n",
      "Progress:  9300\n",
      "Progress:  9400\n",
      "Progress:  9500\n",
      "Progress:  9600\n",
      "Progress:  9700\n",
      "Progress:  9800\n",
      "Progress:  9900\n",
      "Progress:  10000\n",
      "Progress:  10100\n",
      "Progress:  10200\n",
      "Progress:  10300\n",
      "Progress:  10400\n",
      "Progress:  10500\n",
      "Progress:  10600\n",
      "Progress:  10700\n",
      "Progress:  10800\n",
      "Progress:  10900\n",
      "Progress:  11000\n",
      "Progress:  11100\n",
      "Progress:  11200\n",
      "Progress:  11300\n",
      "Progress:  11400\n",
      "Progress:  11500\n",
      "Progress:  11600\n",
      "Progress:  11700\n",
      "Progress:  11800\n",
      "Progress:  11900\n",
      "Progress:  12000\n",
      "Progress:  12100\n",
      "Progress:  12200\n",
      "Progress:  12300\n",
      "Progress:  12400\n",
      "Progress:  12500\n",
      "Progress:  12600\n",
      "Progress:  12700\n",
      "Progress:  12800\n",
      "Progress:  12900\n",
      "Progress:  13000\n",
      "Progress:  13100\n",
      "Progress:  13200\n",
      "Progress:  13300\n",
      "Progress:  13400\n",
      "Progress:  13500\n",
      "Progress:  13600\n",
      "Progress:  13700\n",
      "Progress:  13800\n",
      "Progress:  13900\n",
      "Done. Remember to remove duplicates and 0s manually from Emolex NEW.csv\n"
     ]
    }
   ],
   "source": [
    "# EMOLEX DUPLICATE FIXER\n",
    "# Creates a new lexicon that gives each duplicate word the average emotion score of all duplicates. If 0s and 1s occur equally often: score becomes 0.\n",
    "# Make sure 'Emolex COURCE.csv' contains the words in the preferred language in the first column\n",
    "# Make sure to remove the first row of the target file 'Emolex NEW.csv' after executing this script.\n",
    "\n",
    "import csv\n",
    "\n",
    "# Define writer\n",
    "\n",
    "# Create destination csv\n",
    "with open('Emolex NEW.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow([\"REMOVE THIS ROW\"])\n",
    "    \n",
    "def csv_add(row):\n",
    "    with open('Emolex NEW.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "wordcount = 0\n",
    "subcount = 0\n",
    "        \n",
    "with open('Emolex SOURCE.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    emolex = csv.reader(x, delimiter=',', quotechar='|')\n",
    "    for row in emolex:\n",
    "        word = row[0]\n",
    "        \n",
    "        duplicatecount = 0\n",
    "        emo1 = 0\n",
    "        emo2 = 0\n",
    "        emo3 = 0\n",
    "        emo4 = 0\n",
    "        emo5 = 0\n",
    "        emo6 = 0\n",
    "        emo7 = 0\n",
    "        emo8 = 0\n",
    "        emo9 = 0\n",
    "        emo10 = 0\n",
    "        \n",
    "        with open('Emolex SOURCE.csv', 'r', encoding=\"utf-8\") as x:\n",
    "            emolex2 = csv.reader(x, delimiter=',', quotechar='|')\n",
    "            for row2 in emolex2:\n",
    "                if row[0] == row2[0]:\n",
    "                    duplicatecount += 1\n",
    "                    if row2[1] != \"\":\n",
    "                        emo1 += 1\n",
    "                    if row2[2] != \"\":\n",
    "                        emo2 += 1\n",
    "                    if row2[3] != \"\":\n",
    "                        emo3 += 1\n",
    "                    if row2[4] != \"\":\n",
    "                        emo4 += 1\n",
    "                    if row2[5] != \"\":\n",
    "                        emo5 += 1\n",
    "                    if row2[6] != \"\":\n",
    "                        emo6 += 1\n",
    "                    if row2[7] != \"\":\n",
    "                        emo7 += 1\n",
    "                    if row2[8] != \"\":\n",
    "                        emo8 += 1\n",
    "                    if row2[9] != \"\":\n",
    "                        emo9 += 1\n",
    "                    if row2[10] != \"\":\n",
    "                        emo10 += 1\n",
    "            if duplicatecount  == 1:\n",
    "                nextrow = [word,emo1,emo2,emo3,emo4,emo5,emo6,emo7,emo8,emo9,emo10,duplicatecount]\n",
    "                csv_add(nextrow)\n",
    "            elif duplicatecount >1:\n",
    "                nemo1 = round(emo1/duplicatecount, 0)\n",
    "                nemo2 = round(emo2/duplicatecount, 0)\n",
    "                nemo3 = round(emo3/duplicatecount, 0)\n",
    "                nemo4 = round(emo4/duplicatecount, 0)\n",
    "                nemo5 = round(emo5/duplicatecount, 0)\n",
    "                nemo6 = round(emo6/duplicatecount, 0)\n",
    "                nemo7 = round(emo7/duplicatecount, 0)\n",
    "                nemo8 = round(emo8/duplicatecount, 0)\n",
    "                nemo9 = round(emo9/duplicatecount, 0)\n",
    "                nemo10 = round(emo10/duplicatecount, 0)\n",
    "\n",
    "                nextrow = [word,nemo1,nemo2,nemo3,nemo4,nemo5,nemo6,nemo7,nemo8,nemo9,nemo10,duplicatecount]\n",
    "                csv_add(nextrow)\n",
    "            else:\n",
    "                print(\"Something went wrong at \",word)\n",
    "\n",
    "            # counter\n",
    "            wordcount += 1\n",
    "            if wordcount == 100:\n",
    "                subcount += 1\n",
    "                wordcount = 0\n",
    "                print(\"Progress: \",subcount*100)\n",
    "\n",
    "print(\"Done. Remember to remove duplicates and 0s manually from Emolex NEW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  rows analyzed.\n",
      "2000  rows analyzed.\n",
      "3000  rows analyzed.\n",
      "4000  rows analyzed.\n",
      "5000  rows analyzed.\n",
      "6000  rows analyzed.\n",
      "7000  rows analyzed.\n",
      "8000  rows analyzed.\n",
      "9000  rows analyzed.\n",
      "10000  rows analyzed.\n",
      "11000  rows analyzed.\n",
      "12000  rows analyzed.\n",
      "13000  rows analyzed.\n",
      "14000  rows analyzed.\n",
      "15000  rows analyzed.\n",
      "16000  rows analyzed.\n",
      "17000  rows analyzed.\n",
      "18000  rows analyzed.\n",
      "19000  rows analyzed.\n",
      "20000  rows analyzed.\n",
      "21000  rows analyzed.\n",
      "22000  rows analyzed.\n",
      "23000  rows analyzed.\n",
      "24000  rows analyzed.\n",
      "25000  rows analyzed.\n",
      "26000  rows analyzed.\n",
      "27000  rows analyzed.\n",
      "28000  rows analyzed.\n",
      "29000  rows analyzed.\n",
      "30000  rows analyzed.\n",
      "31000  rows analyzed.\n",
      "32000  rows analyzed.\n",
      "33000  rows analyzed.\n",
      "34000  rows analyzed.\n",
      "35000  rows analyzed.\n",
      "36000  rows analyzed.\n",
      "37000  rows analyzed.\n",
      "38000  rows analyzed.\n",
      "39000  rows analyzed.\n",
      "40000  rows analyzed.\n",
      "41000  rows analyzed.\n",
      "42000  rows analyzed.\n",
      "43000  rows analyzed.\n",
      "44000  rows analyzed.\n",
      "45000  rows analyzed.\n",
      "46000  rows analyzed.\n",
      "47000  rows analyzed.\n",
      "48000  rows analyzed.\n",
      "49000  rows analyzed.\n",
      "50000  rows analyzed.\n",
      "51000  rows analyzed.\n",
      "52000  rows analyzed.\n",
      "53000  rows analyzed.\n",
      "54000  rows analyzed.\n",
      "55000  rows analyzed.\n",
      "56000  rows analyzed.\n",
      "57000  rows analyzed.\n",
      "58000  rows analyzed.\n",
      "59000  rows analyzed.\n",
      "60000  rows analyzed.\n",
      "61000  rows analyzed.\n",
      "62000  rows analyzed.\n",
      "63000  rows analyzed.\n",
      "64000  rows analyzed.\n",
      "65000  rows analyzed.\n",
      "66000  rows analyzed.\n",
      "67000  rows analyzed.\n",
      "68000  rows analyzed.\n",
      "69000  rows analyzed.\n",
      "70000  rows analyzed.\n",
      "71000  rows analyzed.\n",
      "72000  rows analyzed.\n",
      "73000  rows analyzed.\n",
      "74000  rows analyzed.\n",
      "75000  rows analyzed.\n",
      "76000  rows analyzed.\n",
      "77000  rows analyzed.\n",
      "78000  rows analyzed.\n",
      "79000  rows analyzed.\n",
      "80000  rows analyzed.\n",
      "81000  rows analyzed.\n",
      "82000  rows analyzed.\n",
      "83000  rows analyzed.\n",
      "84000  rows analyzed.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# PATTERN\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from pattern.nl import sentiment\n",
    "\n",
    "firstrow=[\"Medium\", \"Datum\", \"Kop\", \"URL\", \"Pattern\", \"Pattern woorden\"]\n",
    "medium = \"\"\n",
    "datum = \"\"\n",
    "kop = \"\"\n",
    "url = \"\"\n",
    "pattern = \"\"\n",
    "patternwrd = []\n",
    "\n",
    "# Create destination csv\n",
    "with open('Pattern results.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Pattern results.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "count = 0\n",
    "subcount = 0\n",
    "        \n",
    "# Open data\n",
    "with open('ALLE DATA def.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "\n",
    "    for row in data:\n",
    "        medium = row[0]\n",
    "        datum = row[1]\n",
    "        kop = row[2]\n",
    "        url = row[3]\n",
    "        score = sentiment(kop)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        patternwrd = []\n",
    "        lowerkop = re.sub('[^A-Za-z0-9 ]+', '', kop).lower()\n",
    "        \n",
    "        with open('Pattern lexicon.csv', 'r', encoding=\"utf-8\") as y:\n",
    "            patternlex = csv.reader(y, delimiter=';', quotechar='|')\n",
    "            \n",
    "            for word in patternlex:\n",
    "                wrd = \"\"\n",
    "                if word[0] in str(lowerkop).split():\n",
    "                    wrd += word[0]\n",
    "                    wrd += \" \"\n",
    "                    wrd += word[1]\n",
    "                    patternwrd.append(wrd)\n",
    "                    \n",
    "            nextrow = [medium,datum,kop,url,pattern,patternwrd]\n",
    "            \n",
    "            csv_add(nextrow)\n",
    "            count += 1\n",
    "            if count == 1000:\n",
    "                subcount += 1\n",
    "                count = 0\n",
    "                print(subcount*1000,\" rows analyzed.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv ready.\n",
      " 4097\n",
      " 4097\n",
      " 2042\n",
      " 1671\n",
      " 1114\n",
      " 1021\n",
      " 912\n",
      " 912\n",
      " 815\n",
      " 812\n",
      " 751\n",
      " 676\n",
      " 661\n",
      " 592\n",
      " 563\n",
      " 557\n",
      " 555\n",
      " 531\n",
      " 531\n",
      " 528\n",
      " 528\n",
      " 522\n",
      " 509\n",
      " 509\n",
      " 494\n",
      " 494\n",
      " 486\n",
      " 485\n",
      " 485\n",
      " 479\n",
      " 461\n",
      " 459\n",
      " 459\n",
      " 422\n",
      " 416\n",
      " 414\n",
      " 414\n",
      " 406\n",
      " 406\n",
      " 398\n",
      " 381\n",
      " 381\n",
      " 381\n",
      " 363\n",
      " 363\n",
      " 362\n",
      " 362\n",
      " 362\n",
      " 360\n",
      " 360\n",
      " 356\n",
      " 348\n",
      " 330\n",
      " 330\n",
      " 327\n",
      " 327\n",
      " 324\n",
      " 313\n",
      " 299\n",
      " 299\n",
      " 299\n",
      " 299\n",
      " 296\n",
      " 296\n",
      " 276\n",
      " 271\n",
      " 271\n",
      " 270\n",
      " 270\n",
      " 262\n",
      " 262\n",
      " 262\n",
      " 247\n",
      " 244\n",
      " 240\n",
      " 234\n",
      " 234\n",
      " 234\n",
      " 233\n",
      " 226\n",
      " 224\n",
      " 216\n",
      " 216\n",
      " 211\n",
      " 211\n",
      " 210\n",
      " 208\n",
      " 203\n",
      " 203\n",
      " 203\n",
      " 201\n",
      " 199\n",
      " 196\n",
      " 192\n",
      " 190\n",
      " 186\n",
      " 183\n",
      " 183\n",
      " 183\n",
      " 183\n",
      " 179\n",
      " 178\n",
      " 174\n",
      " 172\n",
      " 172\n",
      " 171\n",
      " 170\n",
      " 170\n",
      " 163\n",
      " 162\n",
      " 161\n",
      " 161\n",
      " 161\n",
      " 157\n",
      " 156\n",
      " 156\n",
      " 154\n",
      " 154\n",
      " 154\n",
      " 153\n",
      " 151\n",
      " 151\n",
      " 151\n",
      " 145\n",
      " 145\n",
      " 145\n",
      " 142\n",
      " 141\n",
      " 141\n",
      " 141\n",
      " 138\n",
      " 133\n",
      " 133\n",
      " 132\n",
      " 132\n",
      " 131\n",
      " 131\n",
      " 129\n",
      " 129\n",
      " 127\n",
      " 126\n",
      " 126\n",
      " 126\n",
      " 126\n",
      " 126\n",
      " 125\n",
      " 125\n",
      " 122\n",
      " 122\n",
      " 120\n",
      " 118\n",
      " 117\n",
      " 116\n",
      " 114\n",
      " 114\n",
      " 113\n",
      " 113\n",
      " 111\n",
      " 111\n",
      " 111\n",
      " 110\n",
      " 109\n",
      " 109\n",
      " 107\n",
      " 107\n",
      " 107\n",
      " 105\n",
      " 105\n",
      " 100\n",
      " 100\n",
      " 99\n",
      " 98\n",
      " 98\n",
      " 98\n",
      " 95\n",
      " 95\n",
      " 94\n",
      " 93\n",
      " 93\n",
      " 93\n",
      " 92\n",
      " 92\n",
      " 92\n",
      " 91\n",
      " 91\n",
      " 91\n",
      " 91\n",
      " 87\n",
      " 87\n",
      " 87\n",
      " 87\n",
      " 86\n",
      " 86\n",
      " 86\n",
      " 86\n",
      " 85\n",
      " 85\n",
      " 85\n",
      " 84\n",
      " 84\n",
      " 82\n",
      " 82\n",
      " 79\n",
      " 79\n",
      " 79\n",
      " 78\n",
      " 78\n",
      " 76\n",
      " 76\n",
      " 76\n",
      " 74\n",
      " 74\n",
      " 72\n",
      " 72\n",
      " 72\n",
      " 72\n",
      " 72\n",
      " 72\n",
      " 71\n",
      " 71\n",
      " 70\n",
      " 70\n",
      " 69\n",
      " 69\n",
      " 68\n",
      " 66\n",
      " 66\n",
      " 66\n",
      " 65\n",
      " 64\n",
      " 64\n",
      " 64\n",
      " 64\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 63\n",
      " 61\n",
      " 59\n",
      " 59\n",
      " 58\n",
      " 58\n",
      " 58\n",
      " 58\n",
      " 58\n",
      " 58\n",
      " 58\n",
      " 57\n",
      " 56\n",
      " 56\n",
      " 56\n",
      " 56\n",
      " 56\n",
      " 56\n",
      " 55\n",
      " 55\n",
      " 55\n",
      " 55\n",
      " 55\n",
      " 55\n",
      " 54\n",
      " 54\n",
      " 54\n",
      " 52\n",
      " 52\n",
      " 52\n",
      " 51\n",
      " 51\n",
      " 51\n",
      " 51\n",
      " 51\n",
      " 50\n",
      " 49\n",
      " 49\n",
      " 48\n",
      " 47\n",
      " 46\n",
      " 46\n",
      " 46\n",
      " 46\n",
      " 46\n",
      " 46\n",
      " 46\n",
      " 45\n",
      " 45\n",
      " 45\n",
      " 44\n",
      " 43\n",
      " 43\n",
      " 43\n",
      " 43\n",
      " 43\n",
      " 42\n",
      " 42\n",
      " 42\n",
      " 42\n",
      " 42\n",
      " 42\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 41\n",
      " 40\n",
      " 40\n",
      " 40\n",
      " 40\n",
      " 39\n",
      " 39\n",
      " 39\n",
      " 39\n",
      " 38\n",
      " 38\n",
      " 38\n",
      " 38\n",
      " 38\n",
      " 38\n",
      " 38\n",
      " 37\n",
      " 37\n",
      " 37\n",
      " 37\n",
      " 37\n",
      " 37\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 36\n",
      " 35\n",
      " 35\n",
      " 35\n",
      " 35\n",
      " 35\n",
      " 35\n",
      " 35\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 34\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 33\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 31\n",
      " 31\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 30\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 29\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 28\n",
      " 27\n",
      " 27\n",
      " 27\n",
      " 27\n",
      " 27\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 26\n",
      " 25\n",
      " 25\n",
      " 25\n",
      " 25\n",
      " 25\n",
      " 25\n",
      " 25\n",
      " 24\n",
      " 24\n",
      " 24\n",
      " 24\n",
      " 24\n",
      " 24\n",
      " 24\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 23\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 22\n",
      " 21\n",
      " 21\n",
      " 21\n",
      " 21\n",
      " 21\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 20\n",
      " 19\n",
      " 19\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# PATTERN RESULTS READER\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "firstrow = [\"Word\",\"Frequency\"]\n",
    "\n",
    "# Create destination csv\n",
    "with open('Pattern-freqs.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Pattern-freqs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\".csv ready.\")\n",
    "patternlist = []\n",
    "\n",
    "# Open data\n",
    "with open('Pattern results.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "    for row in data:\n",
    "        wordlist = row[5].replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(\", \")\n",
    "        for word in wordlist:\n",
    "            patternlist.append(word)\n",
    "\n",
    "patterncount = Counter(patternlist).most_common(500)\n",
    "for i in patterncount[1:]:\n",
    "#     word = str(i)\n",
    "#     item = re.sub('[^A-Za-z0-9]+', '', word)\n",
    "\n",
    "    listitem = str(i).split(',')\n",
    "    wrd = listitem[0].replace(\"('\",\"\")\n",
    "    frq = listitem[1].replace(\")\",\"\")\n",
    "    print(frq)\n",
    "    nextrow = [wrd,frq]\n",
    "    csv_add(nextrow)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  rows analyzed.\n",
      "2000  rows analyzed.\n",
      "3000  rows analyzed.\n",
      "4000  rows analyzed.\n",
      "5000  rows analyzed.\n",
      "6000  rows analyzed.\n",
      "7000  rows analyzed.\n",
      "8000  rows analyzed.\n",
      "9000  rows analyzed.\n",
      "10000  rows analyzed.\n",
      "11000  rows analyzed.\n",
      "12000  rows analyzed.\n",
      "13000  rows analyzed.\n",
      "14000  rows analyzed.\n",
      "15000  rows analyzed.\n",
      "16000  rows analyzed.\n",
      "17000  rows analyzed.\n",
      "18000  rows analyzed.\n",
      "19000  rows analyzed.\n",
      "20000  rows analyzed.\n",
      "21000  rows analyzed.\n",
      "22000  rows analyzed.\n",
      "23000  rows analyzed.\n",
      "24000  rows analyzed.\n",
      "25000  rows analyzed.\n",
      "26000  rows analyzed.\n",
      "27000  rows analyzed.\n",
      "28000  rows analyzed.\n",
      "29000  rows analyzed.\n",
      "30000  rows analyzed.\n",
      "31000  rows analyzed.\n",
      "32000  rows analyzed.\n",
      "33000  rows analyzed.\n",
      "34000  rows analyzed.\n",
      "35000  rows analyzed.\n",
      "36000  rows analyzed.\n",
      "37000  rows analyzed.\n",
      "38000  rows analyzed.\n",
      "39000  rows analyzed.\n",
      "40000  rows analyzed.\n",
      "41000  rows analyzed.\n",
      "42000  rows analyzed.\n",
      "43000  rows analyzed.\n",
      "44000  rows analyzed.\n",
      "45000  rows analyzed.\n",
      "46000  rows analyzed.\n",
      "47000  rows analyzed.\n",
      "48000  rows analyzed.\n",
      "49000  rows analyzed.\n",
      "50000  rows analyzed.\n",
      "51000  rows analyzed.\n",
      "52000  rows analyzed.\n",
      "53000  rows analyzed.\n",
      "54000  rows analyzed.\n",
      "55000  rows analyzed.\n",
      "56000  rows analyzed.\n",
      "57000  rows analyzed.\n",
      "58000  rows analyzed.\n",
      "59000  rows analyzed.\n",
      "60000  rows analyzed.\n",
      "61000  rows analyzed.\n",
      "62000  rows analyzed.\n",
      "63000  rows analyzed.\n",
      "64000  rows analyzed.\n",
      "65000  rows analyzed.\n",
      "66000  rows analyzed.\n",
      "67000  rows analyzed.\n",
      "68000  rows analyzed.\n",
      "69000  rows analyzed.\n",
      "70000  rows analyzed.\n",
      "71000  rows analyzed.\n",
      "72000  rows analyzed.\n",
      "73000  rows analyzed.\n",
      "74000  rows analyzed.\n",
      "75000  rows analyzed.\n",
      "76000  rows analyzed.\n",
      "77000  rows analyzed.\n",
      "78000  rows analyzed.\n",
      "79000  rows analyzed.\n",
      "80000  rows analyzed.\n",
      "81000  rows analyzed.\n",
      "82000  rows analyzed.\n",
      "83000  rows analyzed.\n",
      "84000  rows analyzed.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# EMOLEX + PATTERN\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from pattern.nl import sentiment\n",
    "\n",
    "firstrow=[\"Medium\", \"Datum\", \"Kop\", \"URL\", \"Pattern\", \"Positive count\", \"Positive list\", \"Negative count\", \"Negative list\", \"Anger count\", \"Anger list\", \"Anticipation count\", \"Anticipation\", \"Disgust count\", \"Disgust list\", \"Fear count\", \"Fear list\", \"Joy count\", \"Joy list\", \"Sadness count\", \"Sadness list\", \"Surprise count\", \"Surprise list\", \"Trust count\", \"Trust list\"]\n",
    "medium = \"\"\n",
    "datum = \"\"\n",
    "kop = \"\"\n",
    "url = \"\"\n",
    "pattern = \"\"\n",
    "poslst = []\n",
    "neglst = []\n",
    "anglst = []\n",
    "antlst = []\n",
    "dislst = []\n",
    "fealst = []\n",
    "joylst = []\n",
    "sadlst = []\n",
    "surlst = []\n",
    "trulst = []\n",
    "poscnt = 0\n",
    "negcnt = 0\n",
    "angcnt = 0\n",
    "antcnt = 0\n",
    "discnt = 0\n",
    "feacnt = 0\n",
    "joycnt = 0\n",
    "sadcnt = 0\n",
    "surcnt = 0\n",
    "trucnt = 0\n",
    "\n",
    "# Create destination csv\n",
    "with open('Sentiment analysis results.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Sentiment analysis results.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "count = 0\n",
    "subcount = 0\n",
    "\n",
    "# Open data\n",
    "with open('ALLE DATA def.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "\n",
    "    for row in data:\n",
    "        poslst = []\n",
    "        neglst = []\n",
    "        anglst = []\n",
    "        antlst = []\n",
    "        dislst = []\n",
    "        fealst = []\n",
    "        joylst = []\n",
    "        sadlst = []\n",
    "        surlst = []\n",
    "        trulst = []\n",
    "        poscnt = 0\n",
    "        negcnt = 0\n",
    "        angcnt = 0\n",
    "        antcnt = 0\n",
    "        discnt = 0\n",
    "        feacnt = 0\n",
    "        joycnt = 0\n",
    "        sadcnt = 0\n",
    "        surcnt = 0\n",
    "        trucnt = 0\n",
    "\n",
    "        medium = row[0]\n",
    "        datum = row[1]\n",
    "        kop = row[2]\n",
    "        url = row[3]\n",
    "        \n",
    "        score = sentiment(kop)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        \n",
    "        lowerkop = re.sub('[^A-Za-z0-9 ]+', '', kop).lower()\n",
    "\n",
    "        # Open emolex\n",
    "        with open('Emolex DEF.csv', 'r', encoding=\"utf-8\") as y:\n",
    "            emolex = csv.reader(y, delimiter=';', quotechar='|')\n",
    "#             print(str(lowerkop).split())\n",
    "            \n",
    "            for word in emolex:\n",
    "                if word[0] in str(lowerkop).split():\n",
    "#                     print(\"FOUND \", word[0])\n",
    "                    # positive\n",
    "                    if word[1] != \"\":\n",
    "                        poslst.append(word[0])\n",
    "                        poscnt += 1\n",
    "                    # negative\n",
    "                    if word[2] != \"\":\n",
    "                        neglst.append(word[0])\n",
    "                        negcnt += 1\n",
    "                    # anger\n",
    "                    if word[3] != \"\":\n",
    "                        anglst.append(word[0])\n",
    "                        angcnt += 1\n",
    "                    # anticipation\n",
    "                    if word[4] != \"\":\n",
    "                        antlst.append(word[0])\n",
    "                        antcnt += 1\n",
    "                    # disgust\n",
    "                    if word[5] != \"\":\n",
    "                        dislst.append(word[0])\n",
    "                        discnt += 1\n",
    "                    # fear\n",
    "                    if word[6] != \"\":\n",
    "                        fealst.append(word[0])\n",
    "                        feacnt += 1\n",
    "                    # joy\n",
    "                    if word[7] != \"\":\n",
    "                        joylst.append(word[0])\n",
    "                        joycnt += 1\n",
    "                    # sadness\n",
    "                    if word[8] != \"\":\n",
    "                        sadlst.append(word[0])\n",
    "                        sadcnt += 1\n",
    "                    # surprise\n",
    "                    if word[9] != \"\":\n",
    "                        surlst.append(word[0])\n",
    "                        surcnt += 1\n",
    "                    # trust\n",
    "                    if word[10] != \"\":\n",
    "                        trulst.append(word[0])\n",
    "                        trucnt += 1\n",
    "                        \n",
    "            nextrow = [medium,datum,kop,url,pattern,poscnt,poslst,negcnt,neglst,angcnt,anglst,antcnt,antlst,discnt,dislst,feacnt,fealst,joycnt,joylst,sadcnt,sadlst,surcnt,surlst,trucnt,trulst]\n",
    "\n",
    "            csv_add(nextrow)\n",
    "            count += 1\n",
    "            if count == 1000:\n",
    "                subcount += 1\n",
    "                count = 0\n",
    "                print(subcount*1000,\" rows analyzed.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv ready.\n",
      "Telegraaf Nexis  listed:  0\n",
      "NRC  listed:  899\n",
      "NOS  listed:  1159\n",
      "Trouw  listed:  698\n",
      "De Volkskrant  listed:  863\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# EMOLEX RESULTS READER WITH DATE FILTER AND PATTERN SCORE, WHICH DISTINGUISHES BETWEEN MEDIA\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "from pattern.nl import sentiment\n",
    "\n",
    "wrd = \"\"\n",
    "frq = \"\"\n",
    "poslst = []\n",
    "neglst = []\n",
    "anglst = []\n",
    "antlst = []\n",
    "dislst = []\n",
    "fealst = []\n",
    "joylst = []\n",
    "sadlst = []\n",
    "surlst = []\n",
    "trulst = []\n",
    "\n",
    "firstrow = [\"Medium\",\"Emotion\",\"Word\",\"Frequency\",\"Pattern\"]\n",
    "\n",
    "# Create destination csv\n",
    "with open('Emolex-freqs.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Emolex-freqs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\".csv ready.\")\n",
    "\n",
    "# Open data\n",
    "filterlist = [\"Telegraaf Nexis\",\"NRC\",\"NOS\",\"Trouw\",\"De Volkskrant\"]\n",
    "for name in filterlist:\n",
    "    poslst = []\n",
    "    neglst = []\n",
    "    anglst = []\n",
    "    antlst = []\n",
    "    dislst = []\n",
    "    fealst = []\n",
    "    joylst = []\n",
    "    sadlst = []\n",
    "    surlst = []\n",
    "    trulst = []\n",
    "    filtercount = 0\n",
    "    with open('SA resultaten.csv', 'r', encoding=\"utf-8\") as x:\n",
    "        data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "        for row in data:\n",
    "            medium = row[0]\n",
    "            date = row[1].split(\"/\")\n",
    "\n",
    "            try:\n",
    "                year = date[2]\n",
    "                month = date[1]\n",
    "            except:\n",
    "                year = \"na\"\n",
    "                month = \"na\"\n",
    "\n",
    "            if medium == name:\n",
    "#                 if year:\n",
    "                if year == \"2020\":\n",
    "#                     if month:\n",
    "                    if month == \"03\":\n",
    "                        filtercount += 1\n",
    "                        for word in row[6].strip('][').split(', '):\n",
    "                            poslst.append(word)\n",
    "                        for word in row[8].strip('][').split(', '):\n",
    "                            neglst.append(word)\n",
    "                        for word in row[10].strip('][').split(', '):\n",
    "                            anglst.append(word)\n",
    "                        for word in row[12].strip('][').split(', '):\n",
    "                            dislst.append(word)\n",
    "                        for word in row[14].strip('][').split(', '):\n",
    "                            fealst.append(word)\n",
    "                        for word in row[16].strip('][').split(', '):\n",
    "                            joylst.append(word)\n",
    "                        for word in row[18].strip('][').split(', '):\n",
    "                            sadlst.append(word)\n",
    "\n",
    "# CHECK IF TELEGRAAF IS BROKEN (it's not)\n",
    "#     if name == \"Telegraaf Nexis\":\n",
    "#         tcount = 0\n",
    "#         print(\"TELEGRAAF: \",Counter(poslst).most_common(500))\n",
    "#         poscnt = Counter(poslst).most_common(1000)\n",
    "#         for i in poscnt[1:]:\n",
    "#             word = str(i)\n",
    "#             item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "#             listitem = item.replace(\" \",\"\").split(',')\n",
    "#             wrd = listitem[0]\n",
    "#             frq = listitem[1]\n",
    "#             nr = int(frq)\n",
    "#             tcount += nr\n",
    "#         print(\"COUNT: \",tcount)\n",
    "\n",
    "    poscnt = Counter(poslst).most_common(11)\n",
    "    emotion = \"POSITIVE\"\n",
    "    for i in poscnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    negcnt = Counter(neglst).most_common(11)\n",
    "    emotion = \"NEGATIVE\"\n",
    "    for i in negcnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    angcnt = Counter(anglst).most_common(11)\n",
    "    emotion = \"ANGER\"\n",
    "    for i in angcnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    discnt = Counter(dislst).most_common(11)\n",
    "    emotion = \"DISGUST\"\n",
    "    for i in discnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    feacnt = Counter(fealst).most_common(11)\n",
    "    emotion = \"FEAR\"\n",
    "    for i in feacnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    joycnt = Counter(joylst).most_common(11)\n",
    "    emotion = \"JOY\"\n",
    "    for i in joycnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "\n",
    "    sadcnt = Counter(sadlst).most_common(11)\n",
    "    emotion = \"SADNESS\"\n",
    "    for i in sadcnt[1:]:\n",
    "        word = str(i)\n",
    "        item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "        listitem = item.replace(\" \",\"\").split(',')\n",
    "        wrd = listitem[0]\n",
    "        frq = listitem[1]\n",
    "        score = sentiment(wrd)\n",
    "        pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "        nextrow = [name,emotion,wrd,frq,pattern]\n",
    "        csv_add(nextrow)\n",
    "              \n",
    "    print(name, \" listed: \",filtercount)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bc3fea17d0eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mnextrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtelegraafemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtelegraafwrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtelegraaffrq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrcemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrcwrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrcfrq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnosemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoswrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnosfrq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrouwemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrouwwrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrouwfrq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvolkskrantemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvolkskrantwrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvolkskrantfrq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mcsv_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# PUT ROWS NEXT TO EACH OTHER FOR COMPARISON (BROKEN)\n",
    "\n",
    "import csv\n",
    "\n",
    "firstrow = [\"Telegraaf\",\"-\",\"-\",\"NRC\",\"-\",\"-\",\"NOS\",\"-\",\"-\",\"Trouw\",\"-\",\"-\",\"Volkskrant\",\"-\",\"-\",]\n",
    "# Create destination csv\n",
    "with open('Emolex-freqs-comparison.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Emolex-freqs-comparison.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "telegraafemo = []\n",
    "telegraafwrd = []\n",
    "telegraaffrq = []\n",
    "nrcemo = []\n",
    "nrcwrd = []\n",
    "nrcfrq = []\n",
    "nosemo = []\n",
    "noswrd = []\n",
    "nosfrq = []\n",
    "trouwemo = []\n",
    "trouwwrd = []\n",
    "trouwfrq = []\n",
    "volkskrantemo = []\n",
    "volkskrantwrd = []\n",
    "volkskrantfrq = []\n",
    "        \n",
    "with open('Emolex-freqs.csv', 'r', encoding=\"utf-8\") as x:\n",
    "    data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "    for row in data:\n",
    "        if row[0] == \"Telegraaf Nexis\":\n",
    "            telegraafemo.append(row[1])\n",
    "            telegraafwrd.append(row[2])\n",
    "            telegraaffrq.append(row[3])\n",
    "        elif row[0] == \"NRC\":\n",
    "            nrcemo.append(row[1])\n",
    "            nrcwrd.append(row[2])\n",
    "            nrcfrq.append(row[3])\n",
    "        elif row[0] == \"NOS\":\n",
    "            nosemo.append(row[1])\n",
    "            noswrd.append(row[2])\n",
    "            nosfrq.append(row[3])\n",
    "        elif row[0] == \"Trouw\":\n",
    "            trouwemo.append(row[1])\n",
    "            trouwwrd.append(row[2])\n",
    "            trouwfrq.append(row[3])\n",
    "        elif row[0] == \"De Volkskrant\":\n",
    "            volkskrantemo.append(row[1])\n",
    "            volkskrantwrd.append(row[2])\n",
    "            volkskrantfrq.append(row[3])\n",
    "\n",
    "for i in range(0,101):\n",
    "    nextrow = [telegraafemo[i],telegraafwrd[i],telegraaffrq[i],nrcemo[i],nrcwrd[i],nrcfrq[i],nosemo[i],noswrd[i],nosfrq[i],trouwemo[i],trouwwrd[i],trouwfrq[i],volkskrantemo[i],volkskrantwrd[i],volkskrantfrq[i],]\n",
    "    csv_add(nextrow)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 416\n",
      "op 233\n",
      "de 215\n",
      "van 208\n",
      "voor 192\n",
      "en 175\n",
      "met 159\n",
      "het 119\n",
      "bij 99\n",
      "een 96\n",
      "na 94\n",
      "corona 93\n",
      "niet 90\n",
      "door 89\n",
      "over 87\n",
      "naar 85\n",
      "is 84\n",
      "te 84\n",
      "aan 77\n",
      "om 62\n",
      "Trump 52\n",
      "zijn 46\n",
      "nog 45\n",
      "tegen 44\n",
      "uit 42\n",
      "maar 40\n",
      "weer 39\n",
      "meer 38\n",
      "geen 38\n",
      "dat 38\n",
      "heeft 36\n",
      "nieuwe 35\n",
      "je 35\n",
      "gaat 33\n",
      "dan 33\n",
      "coronavirus 33\n",
      "zich 32\n",
      "als 31\n",
      " 31\n",
      "ik 31\n",
      "ook 31\n",
      "LIVE 30\n",
      "oktober 29\n",
      "tot 27\n",
      "coronapatinten 26\n",
      "jaar 25\n",
      "moet 25\n",
      "al 25\n",
      "De 24\n",
      "test 23\n",
      "besmet 23\n",
      "kan 23\n",
      "mensen 23\n",
      "er 22\n",
      "positieve 22\n",
      "ziekenhuis 21\n",
      "Ik 21\n",
      "wil 21\n",
      "lockdown 21\n",
      "terug 20\n",
      "die 20\n",
      "nu 20\n",
      "wordt 20\n",
      "Column 20\n",
      "mijn 19\n",
      "af 19\n",
      "Nederland 19\n",
      "nieuws 19\n",
      "wel 19\n",
      "dit 18\n",
      "positief 17\n",
      "achter 17\n",
      "onder 17\n",
      "mee 17\n",
      "AZ 17\n",
      "coronabesmettingen 16\n",
      "zet 16\n",
      "moeten 16\n",
      "VS 16\n",
      "Duitsland 16\n",
      "twee 16\n",
      "Europa 16\n",
      "was 16\n",
      "of 15\n",
      "Kort 15\n",
      "krijgt 15\n",
      "besmettingen 15\n",
      "Aantal 14\n",
      "tijdens 14\n",
      "corona 14\n",
      "drie 14\n",
      "per 14\n",
      "blijft 14\n",
      "Jong 14\n",
      "Corona 13\n",
      "We 13\n",
      "miljoen 13\n",
      "deze 13\n",
      "Giro 13\n",
      "Kort 13\n",
      "in 260\n",
      "de 203\n",
      "op 125\n",
      "en 125\n",
      "van 111\n",
      "voor 109\n",
      "het 104\n",
      "met 96\n",
      "een 77\n",
      "niet 70\n",
      "is 63\n",
      "te 54\n",
      "bij 53\n",
      "over 50\n",
      "door 49\n",
      "meer 48\n",
      "Trump 46\n",
      "nieuwe 46\n",
      "aan 44\n",
      "naar 43\n",
      "De 41\n",
      "om 39\n",
      "corona 38\n",
      "zijn 37\n",
      "maar 33\n",
      "positieve 32\n",
      "na 32\n",
      "nog 32\n",
      "dan 31\n",
      "weer 29\n",
      "dat 28\n",
      "coronavirus 28\n",
      "uit 27\n",
      "geen 27\n",
      "maatregelen 26\n",
      "wil 25\n",
      "lockdown 25\n",
      "Nederland 24\n",
      "nu 24\n",
      "coronapatinten 24\n",
      "kan 23\n",
      "moet 23\n",
      "tot 22\n",
      "als 22\n",
      "besmettingen 21\n",
      "ook 20\n",
      "tweede 20\n",
      "coronamaatregelen 19\n",
      "tegen 19\n",
      "besmet 18\n",
      "positief 18\n",
      "er 18\n",
      "coronacrisis 18\n",
      " 18\n",
      "In 17\n",
      "die 17\n",
      "Rutte 16\n",
      "je 16\n",
      "Hoe 16\n",
      "we 16\n",
      "miljoen 15\n",
      "Het 15\n",
      "gaat 15\n",
      "aantal 15\n",
      "wel 15\n",
      "Een 15\n",
      "minder 15\n",
      "heeft 15\n",
      "jaar 15\n",
      "RIVM 14\n",
      "Duitsland 14\n",
      "zorg 14\n",
      "ziekenhuis 14\n",
      "worden 13\n",
      "Ook 13\n",
      "Kabinet 13\n",
      "andere 13\n",
      "vanwege 13\n",
      "ziekenhuizen 12\n",
      "testen 12\n",
      "neemt 12\n",
      "was 12\n",
      "ruim 12\n",
      "coronatests 12\n",
      "zich 12\n",
      "gaan 12\n",
      "mensen 11\n",
      "moeten 11\n",
      "quarantaine 11\n",
      "snel 11\n",
      "zo 11\n",
      "tijdens 11\n",
      "golf 11\n",
      "veel 11\n",
      "weken 11\n",
      "komt 11\n",
      "vanaf 11\n",
      "Kamer 11\n",
      "Nederlandse 11\n",
      "Aantal 10\n",
      "in 189\n",
      "en 116\n",
      "de 113\n",
      "voor 85\n",
      "op 80\n",
      "van 70\n",
      "het 58\n",
      "met 55\n",
      " 52\n",
      "is 51\n",
      "niet 50\n",
      "over 50\n",
      "bij 49\n",
      "door 48\n",
      "een 40\n",
      "na 40\n",
      " 39\n",
      "maar 38\n",
      "naar 38\n",
      "Trump 35\n",
      "nieuwe 34\n",
      "corona 33\n",
      "te 33\n",
      "tegen 32\n",
      "aan 32\n",
      "meer 28\n",
      "wil 25\n",
      "zijn 24\n",
      "wel 23\n",
      "dat 22\n",
      "ook 22\n",
      "om 22\n",
      "dan 21\n",
      "De 20\n",
      "uit 19\n",
      "weer 19\n",
      "geen 18\n",
      "nu 18\n",
      "zich 18\n",
      "nog 17\n",
      "gaat 17\n",
      "moet 17\n",
      "besmettingen 17\n",
      "heeft 16\n",
      "we 16\n",
      "Van 15\n",
      "tot 15\n",
      "als 15\n",
      "AZ 14\n",
      "coronavirus 14\n",
      "maatregelen 14\n",
      "We 13\n",
      "veel 12\n",
      "mensen 12\n",
      "lockdown 12\n",
      "kan 11\n",
      "positieve 11\n",
      "dit 11\n",
      "PSV 11\n",
      "test 11\n",
      "Ik 11\n",
      "zo 11\n",
      "positief 10\n",
      "jaar 10\n",
      "blijft 10\n",
      "coronapatinten 10\n",
      "dagen 10\n",
      "tweede 10\n",
      "gisteren 10\n",
      "af 10\n",
      "eerste 9\n",
      "Kamer 9\n",
      "besmet 9\n",
      "gaan 9\n",
      "minder 9\n",
      "Kabinet 9\n",
      "Nederland 9\n",
      "kunnen 9\n",
      "je 9\n",
      "ziekenhuis 9\n",
      "Rutte 9\n",
      "onder 9\n",
      "Rutte 9\n",
      "Nederlandse 8\n",
      "of 8\n",
      "Feyenoord 8\n",
      "krijgt 8\n",
      "er 8\n",
      "grote 8\n",
      "ons 8\n",
      "steeds 8\n",
      "Hoe 8\n",
      "Den 8\n",
      "twee 8\n",
      "debat 8\n",
      "Frankrijk 8\n",
      "coronabesmettingen 8\n",
      "quarantaine 8\n",
      "wint 8\n",
      "niet \n",
      "de 258\n",
      "in 141\n",
      "van 140\n",
      "het 134\n",
      "een 118\n",
      "en 99\n",
      "is 94\n",
      "voor 69\n",
      "op 65\n",
      "met 58\n",
      "over 48\n",
      "niet 45\n",
      "zijn 45\n",
      "je 39\n",
      "te 39\n",
      "maar 36\n",
      "De 36\n",
      "aan 34\n",
      "bij 32\n",
      "corona 29\n",
      "Trump 29\n",
      "dat 28\n",
      "die 28\n",
      "geen 27\n",
      "ik 26\n",
      " 25\n",
      "naar 25\n",
      "om 23\n",
      "kan 22\n",
      "als 22\n",
      "er 22\n",
      "Opinie 22\n",
      "door 21\n",
      "nu 21\n",
      "dan 21\n",
      "meer 20\n",
      "na 20\n",
      "of 20\n",
      "nog 20\n",
      "weer 18\n",
      "we 18\n",
      "gaat 18\n",
      "moet 17\n",
      "zich 16\n",
      "tegen 16\n",
      "heeft 16\n",
      "wat 15\n",
      "Hoe 15\n",
      "wel 15\n",
      "Waarom 15\n",
      "wordt 15\n",
      " 15\n",
      "Live 15\n",
      "In 14\n",
      "jaar 14\n",
      "zo 14\n",
      "Een 14\n",
      "wil 13\n",
      "gaan 13\n",
      "uit 13\n",
      "tweede 12\n",
      "maakt 12\n",
      "nieuwe 12\n",
      "Rutte 11\n",
      "ze 11\n",
      "veel 11\n",
      "Wat 11\n",
      "Nederland 11\n",
      "worden 11\n",
      "ook 11\n",
      "coronacrisis 10\n",
      "moeten 10\n",
      "was 10\n",
      "af 10\n",
      "golf 9\n",
      "tot 9\n",
      "ons 9\n",
      "De 8\n",
      "lockdown 8\n",
      "minder 8\n",
      "virus 8\n",
      "mensen 8\n",
      "Ik 8\n",
      "daar 8\n",
      "hebben 8\n",
      "al 8\n",
      "hoe 8\n",
      "Het 8\n",
      "onze 8\n",
      "zit 8\n",
      "twee 8\n",
      "kabinet 8\n",
      "Corona 7\n",
      "mijn 7\n",
      "waar 7\n",
      "Wie 7\n",
      "doen 7\n",
      "hij 7\n",
      "Het 7\n",
      "laat 7\n",
      "de 231\n",
      "in 124\n",
      "het 123\n",
      "van 111\n",
      "is 91\n",
      "een 90\n",
      "en 75\n",
      "op 67\n",
      "voor 66\n",
      "De 56\n",
      "niet 48\n",
      "te 41\n",
      "met 40\n",
      "zijn 39\n",
      "maar 38\n",
      "dat 30\n",
      "er 30\n",
      "over 28\n",
      "om 28\n",
      "aan 27\n",
      "naar 25\n",
      "meer 24\n",
      "die 24\n",
      "nog 24\n",
      "je 23\n",
      "bij 23\n",
      "geen 22\n",
      "Het 22\n",
      "door 21\n",
      "wordt 19\n",
      "kan 18\n",
      "als 18\n",
      "gaat 18\n",
      "tegen 17\n",
      "nu 17\n",
      "dan 17\n",
      "ook 17\n",
      "corona 17\n",
      "Hoe 16\n",
      "In 16\n",
      "wil 16\n",
      "zich 15\n",
      "tot 13\n",
      "uit 13\n",
      "lockdown 13\n",
      "tweede 12\n",
      "Een 12\n",
      "wel 11\n",
      "Trump 11\n",
      "hij 11\n",
      "of 11\n",
      "moet 11\n",
      "weer 10\n",
      "maakt 10\n",
      "ze 10\n",
      "deze 10\n",
      "moeten 10\n",
      "Deze 9\n",
      "we 9\n",
      "Nederland 9\n",
      "Het 8\n",
      "eigen 8\n",
      "was 8\n",
      "mensen 8\n",
      "tijdens 8\n",
      "laten 8\n",
      "heeft 8\n",
      "na 8\n",
      "Dit 8\n",
      "onze 7\n",
      "Rutte 7\n",
      "n 7\n",
      "hard 7\n",
      "Ik 7\n",
      "aantal 7\n",
      "ik 7\n",
      "Wat 7\n",
      "af 7\n",
      "besmettingen 7\n",
      "coronacrisis 7\n",
      "maatregelen 7\n",
      "komt 7\n",
      "jaar 7\n",
      "krijgt 6\n",
      "zorgt 6\n",
      "ziekenhuis 6\n",
      "iets 6\n",
      "VS 6\n",
      "wl 6\n",
      "Jonge 6\n",
      "nieuwe 6\n",
      "al 6\n",
      "goed 6\n",
      "vooral 6\n",
      "gaan 6\n",
      "leven 6\n",
      "maken 6\n",
      "loopt 6\n",
      "werk 6\n",
      "hoe 6\n",
      "['in', '416', 'in', '260', 'in', '189', 'de', '231', 'de', '258']\n",
      "['op', '233', 'de', '203', 'en', '116', 'in', '124', 'in', '141']\n",
      "['de', '215', 'op', '125', 'de', '113', 'het', '123', 'van', '140']\n",
      "['van', '208', 'en', '125', 'voor', '85', 'van', '111', 'het', '134']\n",
      "['voor', '192', 'van', '111', 'op', '80', 'is', '91', 'een', '118']\n",
      "['en', '175', 'voor', '109', 'van', '70', 'een', '90', 'en', '99']\n",
      "['met', '159', 'het', '104', 'het', '58', 'en', '75', 'is', '94']\n",
      "['het', '119', 'met', '96', 'met', '55', 'op', '67', 'voor', '69']\n",
      "['bij', '99', 'een', '77', '', '52', 'voor', '66', 'op', '65']\n",
      "['een', '96', 'niet', '70', 'is', '51', 'De', '56', 'met', '58']\n",
      "['na', '94', 'is', '63', 'niet', '50', 'niet', '48', 'over', '48']\n",
      "['corona', '93', 'te', '54', 'over', '50', 'te', '41', 'niet', '45']\n",
      "['niet', '90', 'bij', '53', 'bij', '49', 'met', '40', 'zijn', '45']\n",
      "['door', '89', 'over', '50', 'door', '48', 'zijn', '39', 'je', '39']\n",
      "['over', '87', 'door', '49', 'een', '40', 'maar', '38', 'te', '39']\n",
      "['naar', '85', 'meer', '48', 'na', '40', 'dat', '30', 'maar', '36']\n",
      "['is', '84', 'Trump', '46', '', '39', 'er', '30', 'De', '36']\n",
      "['te', '84', 'nieuwe', '46', 'maar', '38', 'over', '28', 'aan', '34']\n",
      "['aan', '77', 'aan', '44', 'naar', '38', 'om', '28', 'bij', '32']\n",
      "['om', '62', 'naar', '43', 'Trump', '35', 'aan', '27', 'corona', '29']\n",
      "['Trump', '52', 'De', '41', 'nieuwe', '34', 'naar', '25', 'Trump', '29']\n",
      "['zijn', '46', 'om', '39', 'corona', '33', 'meer', '24', 'dat', '28']\n",
      "['nog', '45', 'corona', '38', 'te', '33', 'die', '24', 'die', '28']\n",
      "['tegen', '44', 'zijn', '37', 'tegen', '32', 'nog', '24', 'geen', '27']\n",
      "['uit', '42', 'maar', '33', 'aan', '32', 'je', '23', 'ik', '26']\n",
      "['maar', '40', 'positieve', '32', 'meer', '28', 'bij', '23', '', '25']\n",
      "['weer', '39', 'na', '32', 'wil', '25', 'geen', '22', 'naar', '25']\n",
      "['meer', '38', 'nog', '32', 'zijn', '24', 'Het', '22', 'om', '23']\n",
      "['geen', '38', 'dan', '31', 'wel', '23', 'door', '21', 'kan', '22']\n",
      "['dat', '38', 'weer', '29', 'dat', '22', 'wordt', '19', 'als', '22']\n",
      "['heeft', '36', 'dat', '28', 'ook', '22', 'kan', '18', 'er', '22']\n",
      "['nieuwe', '35', 'coronavirus', '28', 'om', '22', 'als', '18', 'Opinie', '22']\n",
      "['je', '35', 'uit', '27', 'dan', '21', 'gaat', '18', 'door', '21']\n",
      "['gaat', '33', 'geen', '27', 'De', '20', 'tegen', '17', 'nu', '21']\n",
      "['dan', '33', 'maatregelen', '26', 'uit', '19', 'nu', '17', 'dan', '21']\n",
      "['coronavirus', '33', 'wil', '25', 'weer', '19', 'dan', '17', 'meer', '20']\n",
      "['zich', '32', 'lockdown', '25', 'geen', '18', 'ook', '17', 'na', '20']\n",
      "['als', '31', 'Nederland', '24', 'nu', '18', 'corona', '17', 'of', '20']\n",
      "['', '31', 'nu', '24', 'zich', '18', 'Hoe', '16', 'nog', '20']\n",
      "['ik', '31', 'coronapatinten', '24', 'nog', '17', 'In', '16', 'weer', '18']\n",
      "['ook', '31', 'kan', '23', 'gaat', '17', 'wil', '16', 'we', '18']\n",
      "['LIVE', '30', 'moet', '23', 'moet', '17', 'zich', '15', 'gaat', '18']\n",
      "['oktober', '29', 'tot', '22', 'besmettingen', '17', 'tot', '13', 'moet', '17']\n",
      "['tot', '27', 'als', '22', 'heeft', '16', 'uit', '13', 'zich', '16']\n",
      "['coronapatinten', '26', 'besmettingen', '21', 'we', '16', 'lockdown', '13', 'tegen', '16']\n",
      "['jaar', '25', 'ook', '20', 'Van', '15', 'tweede', '12', 'heeft', '16']\n",
      "['moet', '25', 'tweede', '20', 'tot', '15', 'Een', '12', 'wat', '15']\n",
      "['al', '25', 'coronamaatregelen', '19', 'als', '15', 'wel', '11', 'Hoe', '15']\n",
      "['De', '24', 'tegen', '19', 'AZ', '14', 'Trump', '11', 'wel', '15']\n",
      "['test', '23', 'besmet', '18', 'coronavirus', '14', 'hij', '11', 'Waarom', '15']\n",
      "['besmet', '23', 'positief', '18', 'maatregelen', '14', 'of', '11', 'wordt', '15']\n",
      "['kan', '23', 'er', '18', 'We', '13', 'moet', '11', '', '15']\n",
      "['mensen', '23', 'coronacrisis', '18', 'veel', '12', 'weer', '10', 'Live', '15']\n",
      "['er', '22', '', '18', 'mensen', '12', 'maakt', '10', 'In', '14']\n",
      "['positieve', '22', 'In', '17', 'lockdown', '12', 'ze', '10', 'jaar', '14']\n",
      "['ziekenhuis', '21', 'die', '17', 'kan', '11', 'deze', '10', 'zo', '14']\n",
      "['Ik', '21', 'Rutte', '16', 'positieve', '11', 'moeten', '10', 'Een', '14']\n",
      "['wil', '21', 'je', '16', 'dit', '11', 'Deze', '9', 'wil', '13']\n",
      "['lockdown', '21', 'Hoe', '16', 'PSV', '11', 'we', '9', 'gaan', '13']\n",
      "['terug', '20', 'we', '16', 'test', '11', 'Nederland', '9', 'uit', '13']\n",
      "['die', '20', 'miljoen', '15', 'Ik', '11', 'Het', '8', 'tweede', '12']\n",
      "['nu', '20', 'Het', '15', 'zo', '11', 'eigen', '8', 'maakt', '12']\n",
      "['wordt', '20', 'gaat', '15', 'positief', '10', 'was', '8', 'nieuwe', '12']\n",
      "['Column', '20', 'aantal', '15', 'jaar', '10', 'mensen', '8', 'Rutte', '11']\n",
      "['mijn', '19', 'wel', '15', 'blijft', '10', 'tijdens', '8', 'ze', '11']\n",
      "['af', '19', 'Een', '15', 'coronapatinten', '10', 'laten', '8', 'veel', '11']\n",
      "['Nederland', '19', 'minder', '15', 'dagen', '10', 'heeft', '8', 'Wat', '11']\n",
      "['nieuws', '19', 'heeft', '15', 'tweede', '10', 'na', '8', 'Nederland', '11']\n",
      "['wel', '19', 'jaar', '15', 'gisteren', '10', 'Dit', '8', 'worden', '11']\n",
      "['dit', '18', 'RIVM', '14', 'af', '10', 'onze', '7', 'ook', '11']\n",
      "['positief', '17', 'Duitsland', '14', 'eerste', '9', 'Rutte', '7', 'coronacrisis', '10']\n",
      "['achter', '17', 'zorg', '14', 'Kamer', '9', 'n', '7', 'moeten', '10']\n",
      "['onder', '17', 'ziekenhuis', '14', 'besmet', '9', 'hard', '7', 'was', '10']\n",
      "['mee', '17', 'worden', '13', 'gaan', '9', 'Ik', '7', 'af', '10']\n",
      "['AZ', '17', 'Ook', '13', 'minder', '9', 'aantal', '7', 'golf', '9']\n",
      "['coronabesmettingen', '16', 'Kabinet', '13', 'Kabinet', '9', 'ik', '7', 'tot', '9']\n",
      "['zet', '16', 'andere', '13', 'Nederland', '9', 'Wat', '7', 'ons', '9']\n",
      "['moeten', '16', 'vanwege', '13', 'kunnen', '9', 'af', '7', 'De', '8']\n",
      "['VS', '16', 'ziekenhuizen', '12', 'je', '9', 'besmettingen', '7', 'lockdown', '8']\n",
      "['Duitsland', '16', 'testen', '12', 'ziekenhuis', '9', 'coronacrisis', '7', 'minder', '8']\n",
      "['twee', '16', 'neemt', '12', 'Rutte', '9', 'maatregelen', '7', 'virus', '8']\n",
      "['Europa', '16', 'was', '12', 'onder', '9', 'komt', '7', 'mensen', '8']\n",
      "['was', '16', 'ruim', '12', 'Rutte', '9', 'jaar', '7', 'Ik', '8']\n",
      "['of', '15', 'coronatests', '12', 'Nederlandse', '8', 'krijgt', '6', 'daar', '8']\n",
      "['Kort', '15', 'zich', '12', 'of', '8', 'zorgt', '6', 'hebben', '8']\n",
      "['krijgt', '15', 'gaan', '12', 'Feyenoord', '8', 'ziekenhuis', '6', 'al', '8']\n",
      "['besmettingen', '15', 'mensen', '11', 'krijgt', '8', 'iets', '6', 'hoe', '8']\n",
      "['Aantal', '14', 'moeten', '11', 'er', '8', 'VS', '6', 'Het', '8']\n",
      "['tijdens', '14', 'quarantaine', '11', 'grote', '8', 'wl', '6', 'onze', '8']\n",
      "['corona', '14', 'snel', '11', 'ons', '8', 'Jonge', '6', 'zit', '8']\n",
      "['drie', '14', 'zo', '11', 'steeds', '8', 'nieuwe', '6', 'twee', '8']\n",
      "['per', '14', 'tijdens', '11', 'Hoe', '8', 'al', '6', 'kabinet', '8']\n",
      "['blijft', '14', 'golf', '11', 'Den', '8', 'goed', '6', 'Corona', '7']\n",
      "['Jong', '14', 'veel', '11', 'twee', '8', 'vooral', '6', 'mijn', '7']\n",
      "['Corona', '13', 'weken', '11', 'debat', '8', 'gaan', '6', 'waar', '7']\n",
      "['We', '13', 'komt', '11', 'Frankrijk', '8', 'leven', '6', 'Wie', '7']\n",
      "['miljoen', '13', 'vanaf', '11', 'coronabesmettingen', '8', 'maken', '6', 'doen', '7']\n",
      "['deze', '13', 'Kamer', '11', 'quarantaine', '8', 'loopt', '6', 'hij', '7']\n",
      "['Giro', '13', 'Nederlandse', '11', 'wint', '8', 'werk', '6', 'Het', '7']\n",
      "['Kort', '13', 'Aantal', '10', 'niet', '', 'hoe', '6', 'laat', '7']\n"
     ]
    }
   ],
   "source": [
    "# LIST MOST USED WORDS OVERALL (NOT JUST EMOLEX)\n",
    "\n",
    "firstrow = [\"Telegraaf\",\"-\",\"NRC\",\"-\",\"NOS\",\"-\",\"Trouw\",\"-\",\"Volkskrant\",\"-\",]\n",
    "\n",
    "# Create destination csv\n",
    "with open('Allwords-freqs.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter = \";\")\n",
    "    writer.writerow(firstrow)\n",
    "\n",
    "# Define writer\n",
    "def csv_add(row):\n",
    "    with open('Allwords-freqs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter = \";\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "telegraaflist = []\n",
    "nrclist = []\n",
    "noslist = []\n",
    "trouwlist = []\n",
    "vklist = []\n",
    "        \n",
    "filterlist = [\"Telegraaf Nexis\",\"NRC\",\"NOS\",\"Trouw\",\"De Volkskrant\"]\n",
    "listlist = [telegraaflist, nrclist, noslist, trouwlist, vklist]\n",
    "for i in range(0,5):\n",
    "    filtercount = 0\n",
    "    with open('SA resultaten.csv', 'r', encoding=\"utf-8\") as x:\n",
    "        data = csv.reader(x, delimiter=';', quotechar='|')\n",
    "        for row in data:\n",
    "            medium = row[0]\n",
    "            date = row[1].split(\"/\")\n",
    "\n",
    "            try:\n",
    "                year = date[2]\n",
    "                month = date[1]\n",
    "            except:\n",
    "                year = \"na\"\n",
    "                month = \"na\"\n",
    "\n",
    "            if medium == filterlist[i]:\n",
    "                if year == \"2020\":\n",
    "                    if month == \"10\":\n",
    "                        filtercount += 1\n",
    "                        for word in row[2].split(\" \"):\n",
    "                            listlist[i].append(word)\n",
    "\n",
    "telegraafwrd = []\n",
    "telegraaffrq = []\n",
    "nrcwrd = []\n",
    "nrcfrq = []\n",
    "noswrd = []\n",
    "nosfrq = []\n",
    "trouwwrd = []\n",
    "trouwfrq = []\n",
    "vkwrd = []\n",
    "vkfrq = []\n",
    "\n",
    "mediumwrdlist = [telegraafwrd, nrcwrd, noswrd, trouwwrd, vkwrd]\n",
    "mediumfrqlist = [telegraaffrq, nrcfrq, nosfrq, trouwfrq, vkfrq]\n",
    "\n",
    "# for number in range(0,5):\n",
    "#     counter = Counter(listlist[i]).most_common(100)\n",
    "#     wrdlist = []\n",
    "#     frqlist = []\n",
    "#     for i in counter: \n",
    "#         word = str(i)\n",
    "#         item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "#         listitem = item.replace(\" \",\"\").split(',')\n",
    "#         wrd = str(listitem[0])\n",
    "#         mediumwrdlist[number].append(wrd)\n",
    "#         frq = listitem[1]\n",
    "#         mediumfrqlist[number].append(frq)\n",
    "#         score = sentiment(wrd)\n",
    "#         pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "\n",
    "counter = Counter(telegraaflist).most_common(100)\n",
    "wrdlist = []\n",
    "frqlist = []\n",
    "for i in counter: \n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = str(listitem[0])\n",
    "    telegraafwrd.append(wrd)\n",
    "    frq = listitem[1]\n",
    "    telegraaffrq.append(frq)\n",
    "    score = sentiment(wrd)\n",
    "    pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "\n",
    "counter = Counter(nrclist).most_common(100)\n",
    "wrdlist = []\n",
    "frqlist = []\n",
    "for i in counter: \n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = str(listitem[0])\n",
    "    nrcwrd.append(wrd)\n",
    "    frq = listitem[1]\n",
    "    nrcfrq.append(frq)\n",
    "    score = sentiment(wrd)\n",
    "    pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "    print(wrd, frq)\n",
    "\n",
    "counter = Counter(noslist).most_common(100)\n",
    "wrdlist = []\n",
    "frqlist = []\n",
    "for i in counter: \n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = str(listitem[0])\n",
    "    noswrd.append(wrd)\n",
    "    frq = listitem[1]\n",
    "    nosfrq.append(frq)\n",
    "    score = sentiment(wrd)\n",
    "    pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "    print(wrd, frq)\n",
    "\n",
    "counter = Counter(vklist).most_common(100)\n",
    "wrdlist = []\n",
    "frqlist = []\n",
    "for i in counter: \n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = str(listitem[0])\n",
    "    vkwrd.append(wrd)\n",
    "    frq = listitem[1]\n",
    "    vkfrq.append(frq)\n",
    "    score = sentiment(wrd)\n",
    "    pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "    print(wrd, frq)\n",
    "\n",
    "counter = Counter(trouwlist).most_common(100)\n",
    "wrdlist = []\n",
    "frqlist = []\n",
    "\n",
    "for i in counter: \n",
    "    word = str(i)\n",
    "    item = re.sub('[^A-Za-z0-9 ,]+', '', word)\n",
    "    listitem = item.replace(\" \",\"\").split(',')\n",
    "    wrd = str(listitem[0])\n",
    "    trouwwrd.append(wrd)\n",
    "    frq = listitem[1]\n",
    "    trouwfrq.append(frq)\n",
    "    score = sentiment(wrd)\n",
    "    pattern = str(score).split(\",\")[0].replace(\"(\",\"\")\n",
    "    print(wrd, frq)\n",
    "\n",
    "for i in range(0,100):\n",
    "    nextrow = [\n",
    "        telegraafwrd[i],\n",
    "        telegraaffrq[i],\n",
    "        nrcwrd[i],\n",
    "        nrcfrq[i],\n",
    "        noswrd[i],\n",
    "        nosfrq[i],\n",
    "        trouwwrd[i],\n",
    "        trouwfrq[i],\n",
    "        vkwrd[i],\n",
    "        vkfrq[i]\n",
    "    ]\n",
    "    csv_add(nextrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
